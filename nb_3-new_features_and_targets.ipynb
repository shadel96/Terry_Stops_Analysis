{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Seattle Terry Stop Data Analysis**\n",
    "\n",
    "##### Author: Spencer Hadel\n",
    "***\n",
    "### Overview\n",
    "\n",
    "Recent tensions in the United States have led to a mistrust of police forces across the country, particularly due to the increasing strength of movements such as Black Lives Matter, and increased cultural attention to the racial and ethnic disparity in many facets of life. There is increasing focus on the scope of what police officer's are legally able to do, and whether they use this right fairly.\n",
    "\n",
    "One such disparity has been observed in Terry Stops (also known as 'stop-and-frisks'), when a police officer uses theur right to legally temporarily detain a person based on 'reasonable suspsicion' that the person may be involved in criminal activity. The officer has the right to physically 'frisk' the subject, and take whatever action they feel is necessary properly handle the situation.\n",
    "\n",
    "The newly elected mayor of Seattle campaigned on a platform of police reform, and has hired our agency to analyze, test, and interpret the current Seattle police department's Terry Stop data, so that their selected Chief of Police can make meaningful changes to the system as it stands.\n",
    "\n",
    "### Data\n",
    "This analysis utilizes about 52,000 data entries of Seattly Terry Stops ([from data.seattle.gov](https://data.seattle.gov/Public-Safety/Terry-Stops/28ny-9ts8)), in the file [Terry_Stops.csv](./data/Terry_Stops.csv). This data has been collected from 2015 until the present. A deeper explanation of this dataset and how it was cleaned can be found in the [First Notebook](./nb_1-terry_data_cleaning_analysis.ipynb).\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "# Part 3: Target and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only run classifaction models on one set of features seeking to find one target variable. Going forward, we will test a few different arrangements of features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "from imports import *\n",
    "df = pd.read_csv('data/cleaned_df.csv')\n",
    "\n",
    "#create cummy variables from categorical data\n",
    "dummies_df = pd.get_dummies(df, drop_first=True)\n",
    "dummies_df.columns = dummies_df.columns.str.replace(' ','_')\n",
    "#dummies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a large number of potential features in this dataset, as well as 3 potential targets: Arrested, Legal_Action_Taken, and Physical_Arrest. In the [previous notebook](./terry_models.ipynb) we only attempted to find Physical Arrests using all the data that existed.\n",
    "\n",
    "The first thing we do is see if there are better results with each of our other target variables, using Machine Learning Pipelines to streamline the workflow.\n",
    "\n",
    "We will once again test our data with and without SMOTE since the change in target variables has changed how imbalanced the data is (in this case, it is LESS imbalanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize classifiers\n",
    "clf_forest = RandomForestClassifier(random_state=42)\n",
    "clf_logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf_xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "#parameters for each classifier\n",
    "logreg_param = {}\n",
    "logreg_param['classifier__C'] = np.logspace(-2, 2, 10)\n",
    "logreg_param['classifier__penalty'] = ['l1', 'l2']\n",
    "logreg_param['classifier'] = [clf_logreg]\n",
    "\n",
    "\n",
    "forest_param = {}\n",
    "forest_param['classifier__n_estimators'] = [10,100,1000]\n",
    "forest_param['classifier__max_depth'] = [None, 3, 4, 10]\n",
    "forest_param['classifier__max_features'] = ['sqrt', 'log2', 2, 5, 10],\n",
    "forest_param['classifier'] = [clf_forest]\n",
    "\n",
    "xgb_param = {}\n",
    "xgb_param['classifier__n_estimators'] = [10,100,1000]\n",
    "xgb_param['classifier__learning_rate'] = [0.001, 0.01, 0.1]\n",
    "xgb_param['classifier__subsample'] =  [0.7]\n",
    "xgb_param['classifier__max_depth'] = [9]\n",
    "xgb_param['classifier'] = [clf_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipelines (SMOTE and non SMOTE)\n",
    "pipeline = imbpipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "smote_pipeline = imbpipeline([('sm', SMOTE(random_state = 42)),('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Arrested (Without Synthetic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n"
     ]
    }
   ],
   "source": [
    "# remove other targets\n",
    "dummies_df.drop(['Physical_Arrest', 'Legal_Action_Taken'], axis=1, inplace=True)\n",
    "\n",
    "#prepare data\n",
    "X= dummies_df.drop('Arrested', axis=1)\n",
    "y = dummies_df['Arrested']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# new negative and positive description for visualizations and scoring\n",
    "neg = 'Not Arrested'\n",
    "pos = 'Arrested'\n",
    "\n",
    "#use params established earlier\n",
    "params = [logreg_param, forest_param, xgb_param]\n",
    "\n",
    "#create and fit data using GridSearch and pipeline\n",
    "arrested_cv = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, verbose=True, scoring='f1')\n",
    "arrested_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best parameters as decided by gridsearch\n",
    "arrested_cv.best_params_\n",
    "\n",
    "# {'classifier': XGBClassifier()\n",
    "#  'classifier__learning_rate': 0.1,\n",
    "#  'classifier__max_depth': 9,\n",
    "#  'classifier__n_estimators': 1000,\n",
    "#  'classifier__subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#view scores\n",
    "clf_scores(arrested_cv, X_train, X_test, y_train, y_test, neg, pos)\n",
    "\n",
    "# Train Data:                                 Test Data:\n",
    "# Accuracy:  0.8092303758629507               Accuracy:  0.7264708138375393\n",
    "# Recall:    0.30616488200436637              Recall:    0.1322107888992828\n",
    "# Precision: 0.7891211146838156               Precision: 0.3512841756420878\n",
    "# F1:        0.4411654557711033               F1:        0.19211599456275485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance: \n",
    "# WHATTTTTTTTTTTTTTTTTTT#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Arrested (With Synthetic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat with SMOTE pipeline\n",
    "\n",
    "arrested_smote_cv = GridSearchCV(smote_pipeline, params, cv=3, n_jobs=-1, verbose=True, scoring='f1')\n",
    "arrested_smote_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arrested_smote_cv.best_params_\n",
    "\n",
    "# {'classifier': XGBClassifier()\n",
    "#  'classifier__learning_rate': 0.1,\n",
    "#  'classifier__max_depth': 9,\n",
    "#  'classifier__n_estimators': 10,\n",
    "#  'classifier__subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_scores(arrested_smote_cv, X_train, X_test, y_train, y_test, neg, pos)\n",
    "\n",
    "# Train Data:                                 Test Data:\n",
    "# Accuracy:  0.5920225006392227               Accuracy:  0.5724476489990028\n",
    "# Recall:    0.6382160307724296               Recall:    0.5806049267227938\n",
    "# Precision: 0.32978780553317216              Precision: 0.3056969298965687\n",
    "# F1:        0.43486576468088123              F1:        0.40051624005162395"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance: \n",
    "# WHATTTTTTTTTTTTTTTTTTT#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Legal Action Taken (Without Synthetic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove other targets\n",
    "dummies_df = pd.get_dummies(df, drop_first=True)\n",
    "dummies_df.drop(['Physical_Arrest', 'Arrested'], axis=1, inplace=True)\n",
    "\n",
    "#new variables for vizualizations and scoring\n",
    "neg = 'No Legal Action'\n",
    "pos = 'Legal Action Taken'\n",
    "\n",
    "#prepare dataset fir bew target\n",
    "X= dummies_df.drop('Legal_Action_Taken', axis=1)\n",
    "y = dummies_df['Legal_Action_Taken']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "#create and fit gridsearch\n",
    "legal_cv = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, verbose=True, scoring='f1')\n",
    "legal_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "legal_cv.best_params_\n",
    "\n",
    "# {'classifier': XGBClassifier()\n",
    "#  'classifier__learning_rate': 0.001,\n",
    "#  'classifier__max_depth': 9,\n",
    "#  'classifier__n_estimators': 100,\n",
    "#  'classifier__subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_scores(legal_cv, X_train, X_test, y_train, y_test, neg, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance: \n",
    "# WHATTTTTTTTTTTTTTTTTTT#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Legal Action Taken (With Synthetic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit new gridsearch using pipeline with SMOTE\n",
    "\n",
    "legal_smote_cv = GridSearchCV(smote_pipeline, params, cv=3, n_jobs=-1, verbose=True, scoring='f1')\n",
    "legal_smote_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_smote_cv.best_params_\n",
    "\n",
    "# {'classifier': XGBClassifier()\n",
    "#  'classifier__learning_rate': 0.01,\n",
    "#  'classifier__max_depth': 9,\n",
    "#  'classifier__n_estimators': 1000,\n",
    "#  'classifier__subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scores(legal_smote_cv, X_train, X_test, y_train, y_test, neg, pos)\n",
    "\n",
    "# Train Data:                                 Test Data:\n",
    "# Accuracy:  0.6465354129378675               Accuracy:  0.5879420111988954\n",
    "# Recall:    0.6153539293471034               Recall:    0.5597659885653503\n",
    "# Precision: 0.729570655315571                Precision: 0.6713442832084197\n",
    "# F1:        0.6676124068285645               F1:        0.6104988399071926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance: \n",
    "# WHATTTTTTTTTTTTTTTTTTT#\n",
    "\n",
    "Our most successful model so far: XG Boost testing for Legal Action Taken, without synthetic data (legal_cv), has an F1 score of 0.72 and an Accuracy score of 0.60 on the test data. These are far from ideal outcomes, but at least show that the classifier is better trained than previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importance = xgb_cv.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis\n",
    "\n",
    "The classification models trained with different target variables had significantly different scores, all much better than when the target variable was simply the \"Physical Arrest\" column.\n",
    "\n",
    "So far, however, these models have been trained on every single piece of data in the dataset, with the exception of those that we removed in cleaning. There are two issues with this. \n",
    "\n",
    "First, some of this data could be meaningless to our classifiers, or even worse, generating noise that can cause our model to underperform or overfit.\n",
    "\n",
    "Second, there is a limitation on how much real world information we can take away from training models on the entire dataset. If we want to test the predictions of a model based on Subject demographcis alone, for example, then we would want to remove the demographics for the Officer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking least important features\n",
    "\n",
    "Next we want see what features could be generating noise in the data, using Lasso Regression to indicate which features have the lowest coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using most recent featureset (no changes to df, X, or y needed)\n",
    "\n",
    "#create and fit Lasso Regression model\n",
    "lasso = Lasso(alpha = 0.0001, normalize = False)\n",
    "lasso = lasso.fit(X_train, y_train)\n",
    "\n",
    "#lass model prediction on train data\n",
    "lasso_pred = lasso.predict(X_train)\n",
    "\n",
    "#take transpose of lasso coefficients\n",
    "lasso_coef = pd.DataFrame(data=lasso.coef_).T\n",
    "\n",
    "#rename columns to match features, sort\n",
    "lasso_coef.columns = X_train.columns\n",
    "lasso_coef = lasso_coef.T.sort_values(by=0).T\n",
    "\n",
    "#bar plot of features by importance\n",
    "lasso_coef.plot(kind='bar', legend=True, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list of features by importance\n",
    "lasso_coef.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see by this visualization that specific features are far more impactful on the target, such as \"Subject_Age_Group_1 - 17\t\", and \"Subject_Perceived_Race_Unknown\".\n",
    "\n",
    "All the features that have been reduced to 0 have been selected by Lasso as the least significant to the dataset. We will attempt running the model again to see if there is a change in scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show features that became 0 using Lasso\n",
    "zero_features = lasso_coef.T.index[lasso_coef.T[0] == 0]\n",
    "zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zeroed features from features\n",
    "X_train.drop(zero_features, axis=1, inplace=True)\n",
    "X_test.drop(zero_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced features classifier using best_params from earlier\n",
    "best_xgb = XGBClassifier(learning_rate = 0.01, max_depth = 9, n_estimators = 1000, subsample = 0.7, random_state=42)\n",
    "\n",
    "best_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scores(best_xgb, X_train, X_test, y_train, y_test, neg, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Results\n",
    "\n",
    "The fact that we did not get any improvement in our model, and in fact caused scores to go down by a small margin, shows that the extraneous data was not causing any issue for our classifier.\n",
    "\n",
    "Unfortunately, with the current data, it seems unlikely to help our models perform any better with a binary target. This is most likely due to the variability and lack of clarity in very much of the original data. There is clearly potential for more accurate classifiers, but only with more specific data, or perhaps different configurations of the original dataset.\n",
    "\n",
    "Another potential change that could be made is an adjustment to the type of Classifier. A multiclass or multioutput classifier, or even an unsupervised learning algorithm could find different results, potentially identifying key groups of features that yield different targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "# Baseline Etc\n",
    "\n",
    "# Best\n",
    "\n",
    "# Problems\n",
    "## stadnardized, detailed data\n",
    "## single target\n",
    "\n",
    "# Solutions\n",
    "## more standardization\n",
    "## multi target\n",
    "## separate analysis of performance per officer based on past records\n",
    "\n",
    "As is clear from these tests (and as stated above), there are a vast assortment of possibilities that can be investigated in future analyses. The limitations of a binary target classification algorithm make it challenging to adequately find the results we need to make any sort of substantive reports about the data we have, besides the fact that we need more detailed and standardized data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
